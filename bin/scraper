#!/usr/bin/env ruby
# frozen_string_literal: true

# Main class for scrapping https://www.coldwellbankerhomes.com.
#
# For any state or states must be total scraped 20 000 or more products.
#
# Author::    Alexander Petrov mailto:alex.petrofan@gmail.com
# Link::      https://www.linkedin.com/in/alex-petrov/
class Scraper
  # Site homepage.
  BASE_URL = 'https://www.coldwellbankerhomes.com'
  STATES_URL = 'https://www.coldwellbankerhomes.com/sitemap/real-estate/'

  def initialize; end

  def call
    $stdout.puts '== Scraping... =='
    scrap_data
  end

  private

  def get_page_html(url)
    require 'curb'
    require 'nokogiri'

    get_response = Curl.get(url)
    Nokogiri::HTML(get_response.body_str)
  rescue StandardError => error
    warn '  -- Error during getting page HTML --'
    warn error.inspect
  end

  def scrap_data
    states = parse_states
    $stdout.puts states

    export_to_csv('states', states)

    parse_regions
    parse_products
  end

  def parse_states
    $stdout.puts '== Scraping states page =='
    page_html = get_page_html(STATES_URL)
    return unless page_html

    estates_list = page_html.css('table.table-sort a')
    return unless estates_list

    estates_list.map do |estate_node|
      { name: estate_node.content, url: BASE_URL + estate_node[:href] }
    end
  end

  # TODO: Add implementation, `state` param.
  def parse_regions; end

  # TODO: Add implementation, region` param.
  def parse_products; end

  def export_to_csv(file_name, data)
    require 'csv'

    $stdout.puts "== Exporting #{file_name} to CSV file =="

    CSV.open("output/#{file_name}.csv", 'w') do |csv|
      csv << data.first.keys
      data.each { |record| csv << record.each_value }
    end
  rescue StandardError => error
    warn '  -- Error during saving to CSV file --'
    warn error.inspect
  end
end

Scraper.new.call
