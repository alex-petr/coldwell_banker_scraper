#!/usr/bin/env ruby
# frozen_string_literal: true

# Main class for scrapping https://www.coldwellbankerhomes.com.
#
# For any state or states must be total scraped 20 000 or more products.
#
# Author::    Alexander Petrov mailto:alex.petrofan@gmail.com
# Link::      https://www.linkedin.com/in/alex-petrov/
class Scraper
  # Site homepage.
  URL = 'https://www.coldwellbankerhomes.com/sitemap/real-estate/'

  def initialize; end

  def call
    $stdout.puts '== Scraping... =='
    data = scrap_data
    parse_data(data)
    export_to_csv
  end

  private

  def scrap_data
    require 'curb'

    $stdout.puts '== Scraping states page... =='

    http = Curl.get(URL)
    http.body_str
  end

  def parse_data(data)
    parse_states(data)
    parse_regions
    parse_products
  end

  def parse_states(data)
    require 'nokogiri'

    page_html = Nokogiri::HTML(data)
    return unless page_html

    estates_list = page_html.css('table.table-sort a')

    $stdout.puts estates_list
  end

  # state
  def parse_regions; end

  # region
  def parse_products; end

  def export_to_csv
    require 'csv'

    column_names = %w[street_address state country zip_code price bedrooms
        bathrooms year_built photos url]

    $stdout.puts '== Exporting results to CSV file... =='

    CSV.open('output/products.csv', 'w') do |csv|
      csv << column_names
      csv << %w[data1 data2]
    end
  end
end

Scraper.new.call
